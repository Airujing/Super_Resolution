{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15ip2pLxMBMpHigCfxH_Ym1IjWeBhPMUF",
      "authorship_tag": "ABX9TyOSIgioVD24s6POtCAyRotc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Airujing/Super_Resolution/blob/main/SR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOhqjgT-I8_3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybPUAZMKkwYf",
        "outputId": "d6f9158b-fc8b-4782-c96f-f8ae9f9881b8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLHfb2kGlDnl",
        "outputId": "bb544725-1334-4512-dcaa-0c07c60ffd48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/SwinIR_SR\n",
        "!pwd\n",
        "%ll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2WzNBFMlGFx",
        "outputId": "0bdd4cf3-86d1-4035-abba-226176541e03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SwinIR_SR\n",
            "/content/drive/MyDrive/SwinIR_SR\n",
            "total 298\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 12:24 \u001b[01;34mDIV2K\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mdocs\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mfigs\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mkernels\u001b[0m/\n",
            "-rw------- 1 root  1066 Nov  7 05:57 LICENSE\n",
            "-rw------- 1 root  6688 Nov  7 05:57 main_challenge_sr.py\n",
            "-rw------- 1 root  8602 Nov  7 05:57 main_download_pretrained_models.py\n",
            "-rw------- 1 root  4461 Nov  7 05:57 main_test_dncnn3_deblocking.py\n",
            "-rw------- 1 root  7640 Nov  7 05:57 main_test_dncnn.py\n",
            "-rw------- 1 root  8165 Nov  7 05:57 main_test_dpsr.py\n",
            "-rw------- 1 root  7251 Nov  7 05:57 main_test_face_enhancement.py\n",
            "-rw------- 1 root  7274 Nov  7 05:57 main_test_fdncnn.py\n",
            "-rw------- 1 root  6995 Nov  7 05:57 main_test_ffdnet.py\n",
            "-rw------- 1 root  7953 Nov  7 05:57 main_test_imdn.py\n",
            "-rw------- 1 root  6646 Nov  7 05:57 main_test_ircnn_denoiser.py\n",
            "-rw------- 1 root  8203 Nov  7 05:57 main_test_msrresnet.py\n",
            "-rw------- 1 root  7700 Nov  7 05:57 main_test_rrdb.py\n",
            "-rw------- 1 root 16487 Nov  7 05:57 main_test_rvrt.py\n",
            "-rw------- 1 root  9059 Nov  7 05:57 main_test_srmd.py\n",
            "-rw------- 1 root 13799 Nov  7 05:57 main_test_swinir.py\n",
            "-rw------- 1 root  9288 Nov  7 05:57 main_test_usrnet.py\n",
            "-rw------- 1 root 18786 Nov  7 05:57 main_test_vrt.py\n",
            "-rw------- 1 root  8918 Nov  7 05:57 main_train_dncnn.py\n",
            "-rw------- 1 root  9388 Nov  7 05:57 main_train_drunet.py\n",
            "-rw------- 1 root 10001 Nov  7 05:57 main_train_gan.py\n",
            "-rw------- 1 root  9642 Dec  7 06:21 main_train_psnr.py\n",
            "-rw------- 1 root  8104 Nov  7 05:57 main_train_usrnet.py\n",
            "-rw------- 1 root 14116 Nov  7 05:57 main_train_vrt.py\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mmatlab\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mmodels\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mmodel_zoo\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34moptions\u001b[0m/\n",
            "-rw------- 1 root 20145 Nov  7 05:57 README.md\n",
            "-rw------- 1 root    89 Nov  7 05:57 requirement.txt\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mresults\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mretinaface\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mscripts\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 12:52 \u001b[01;34msuperresolution\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mtestsets\u001b[0m/\n",
            "drwx------ 2 root  4096 Dec  5 06:50 \u001b[01;34mutils\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://cv.snu.ac.kr/research/EDSR/DIV2K.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0pSbzX6sETQ",
        "outputId": "870a904f-373b-4df9-dceb-38a77576981a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-05 12:05:35--  https://cv.snu.ac.kr/research/EDSR/DIV2K.tar\n",
            "Resolving cv.snu.ac.kr (cv.snu.ac.kr)... 147.46.67.83\n",
            "Connecting to cv.snu.ac.kr (cv.snu.ac.kr)|147.46.67.83|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7648665600 (7.1G) [application/x-tar]\n",
            "Saving to: ‘DIV2K.tar’\n",
            "\n",
            "DIV2K.tar           100%[===================>]   7.12G  3.89MB/s    in 18m 12s \n",
            "\n",
            "2024-12-05 12:23:48 (6.68 MB/s) - ‘DIV2K.tar’ saved [7648665600/7648665600]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvf DIV2K.tar -C DIV2K"
      ],
      "metadata": {
        "id": "aXWdoM-pxrc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_train_psnr.py --opt options/swinir/train_swinir_denoising_gray_CN.json\n"
      ],
      "metadata": {
        "id": "9pgthoDS0BWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_test_swinir.py --task real_sr --scale 2 --model_path model_zoo/swinir/SR/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x2_GAN.pth --folder_lq DIV2K/DIV2K/DIV2K_test_LR_unknown/X2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukEEfnEdldTj",
        "outputId": "fea7c1ea-3acf-4f13-d349-5cde92bbb437"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "loading model from model_zoo/swinir/SR/003_realSR_BSRGAN_DFO_s64w8_SwinIR-M_x2_GAN.pth\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "/content/drive/MyDrive/SwinIR_SR/main_test_swinir.py:178: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_model = torch.load(args.model_path)\n",
            "Testing 0 0901x2              \n",
            "Testing 1 0902x2              \n",
            "Testing 2 0903x2              \n",
            "Testing 3 0904x2              \n",
            "Testing 4 0905x2              \n",
            "Testing 5 0906x2              \n",
            "Testing 6 0907x2              \n",
            "Testing 7 0908x2              \n",
            "Testing 8 0909x2              \n",
            "Testing 9 0910x2              \n",
            "Testing 10 0911x2              \n",
            "Testing 11 0912x2              \n",
            "Testing 12 0913x2              \n",
            "Testing 13 0914x2              \n",
            "Testing 14 0915x2              \n",
            "Testing 15 0916x2              \n",
            "Testing 16 0917x2              \n",
            "Testing 17 0918x2              \n",
            "Testing 18 0919x2              \n",
            "Testing 19 0920x2              \n",
            "Testing 20 0921x2              \n",
            "Testing 21 0922x2              \n",
            "Testing 22 0923x2              \n",
            "Testing 23 0924x2              \n",
            "Testing 24 0925x2              \n",
            "Testing 25 0926x2              \n",
            "Testing 26 0927x2              \n",
            "Testing 27 0928x2              \n",
            "Testing 28 0929x2              \n",
            "Testing 29 0930x2              \n",
            "Testing 30 0931x2              \n",
            "Testing 31 0932x2              \n",
            "Testing 32 0933x2              \n",
            "Testing 33 0934x2              \n",
            "Testing 34 0935x2              \n",
            "Testing 35 0936x2              \n",
            "Testing 36 0937x2              \n",
            "Testing 37 0938x2              \n",
            "Testing 38 0939x2              \n",
            "Testing 39 0940x2              \n",
            "Testing 40 0941x2              \n",
            "Testing 41 0942x2              \n",
            "Testing 42 0943x2              \n",
            "Testing 43 0944x2              \n",
            "Testing 44 0945x2              \n",
            "Testing 45 0946x2              \n",
            "Testing 46 0947x2              \n",
            "Testing 47 0948x2              \n",
            "Testing 48 0949x2              \n",
            "Testing 49 0950x2              \n",
            "Testing 50 0951x2              \n",
            "Testing 51 0952x2              \n",
            "Testing 52 0953x2              \n",
            "Testing 53 0954x2              \n",
            "Testing 54 0955x2              \n",
            "Testing 55 0956x2              \n",
            "Testing 56 0957x2              \n",
            "Testing 57 0958x2              \n",
            "Testing 58 0959x2              \n",
            "Testing 59 0960x2              \n",
            "Testing 60 0961x2              \n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "def concatenate_images(original_folder, super_res_folder, output_folder):\n",
        "    original_images = load_images_from_folder(original_folder, '.png')[:12]\n",
        "    super_res_images = load_images_from_folder(super_res_folder, '.bmp')[:12]\n",
        "\n",
        "    print(f\"找到 {len(original_images)} 张原始图像和 {len(super_res_images)} 张超分图像。\")\n",
        "\n",
        "    for (orig_name, orig_img), (super_res_name, super_res_img) in zip(original_images, super_res_images):\n",
        "        print(f\"处理图像: {orig_name} 和 {super_res_name}\")\n",
        "        if orig_name[:-4] == super_res_name[:-4]:  # 比较文件名去掉后缀\n",
        "            # 添加标注\n",
        "            orig_img_annotated = annotate_image(orig_img.copy(), \"Original\")\n",
        "            super_res_img_annotated = annotate_image(super_res_img.copy(), \"Super Res\")\n",
        "\n",
        "            # 拼接四列\n",
        "            combined_img = np.hstack((orig_img_annotated, super_res_img_annotated, orig_img_annotated, super_res_img_annotated))\n",
        "            output_path = os.path.join(output_folder, orig_name)\n",
        "            cv2.imwrite(output_path, combined_img)\n",
        "            print(f\"生成拼接图像: {output_path}\")\n",
        "        else:\n",
        "            print(f\"文件名不匹配: {orig_name} 和 {super_res_name}\")\n",
        "\n",
        "# 运行代码\n",
        "concatenate_images(original_folder, super_res_folder, output_folder)\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder, file_extension):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(file_extension):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                images.append((filename, img))\n",
        "    return images\n",
        "\n",
        "def annotate_image(image, text):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(image, text, (10, 30), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "    return image\n",
        "\n",
        "def concatenate_images(original_folder, super_res_folder, output_folder):\n",
        "    original_images = load_images_from_folder(original_folder, '.png')[:12]\n",
        "    super_res_images = load_images_from_folder(super_res_folder, '.bmp')[:12]\n",
        "\n",
        "    for (orig_name, orig_img), (super_res_name, super_res_img) in zip(original_images, super_res_images):\n",
        "        if orig_name[:-4] == super_res_name[:-4]:  # 比较文件名去掉后缀\n",
        "            # 添加标注\n",
        "            orig_img_annotated = annotate_image(orig_img.copy(), \"Original\")\n",
        "            super_res_img_annotated = annotate_image(super_res_img.copy(), \"Super Res\")\n",
        "\n",
        "            # 拼接四列\n",
        "            combined_img = np.hstack((orig_img_annotated, super_res_img_annotated, orig_img_annotated, super_res_img_annotated))\n",
        "            output_path = os.path.join(output_folder, orig_name)\n",
        "            cv2.imwrite(output_path, combined_img)\n",
        "\n",
        "# 设置文件夹路径\n",
        "original_folder = 'DIV2K/DIV2K/DIV2K_test_LR_unknown/X2'  # PNG 文件夹路径\n",
        "super_res_folder = 'results/swinir_real_sr_x2'  # BMP 文件夹路径\n",
        "output_folder = 'results'  # 输出文件夹路径\n",
        "\n",
        "# 创建输出文件夹（如果不存在）\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 执行拼接\n",
        "concatenate_images(original_folder, super_res_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbAZbXB34RNw",
        "outputId": "a3a2c814-fabc-4820-f645-c65b01d6703c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "找到 12 张原始图像和 12 张超分图像。\n",
            "处理图像: 0903x2.png 和 0901x2.bmp\n",
            "文件名不匹配: 0903x2.png 和 0901x2.bmp\n",
            "处理图像: 0907x2.png 和 0902x2.bmp\n",
            "文件名不匹配: 0907x2.png 和 0902x2.bmp\n",
            "处理图像: 0910x2.png 和 0903x2.bmp\n",
            "文件名不匹配: 0910x2.png 和 0903x2.bmp\n",
            "处理图像: 0906x2.png 和 0904x2.bmp\n",
            "文件名不匹配: 0906x2.png 和 0904x2.bmp\n",
            "处理图像: 0902x2.png 和 0905x2.bmp\n",
            "文件名不匹配: 0902x2.png 和 0905x2.bmp\n",
            "处理图像: 0911x2.png 和 0906x2.bmp\n",
            "文件名不匹配: 0911x2.png 和 0906x2.bmp\n",
            "处理图像: 0904x2.png 和 0907x2.bmp\n",
            "文件名不匹配: 0904x2.png 和 0907x2.bmp\n",
            "处理图像: 0901x2.png 和 0908x2.bmp\n",
            "文件名不匹配: 0901x2.png 和 0908x2.bmp\n",
            "处理图像: 0912x2.png 和 0909x2.bmp\n",
            "文件名不匹配: 0912x2.png 和 0909x2.bmp\n",
            "处理图像: 0909x2.png 和 0910x2.bmp\n",
            "文件名不匹配: 0909x2.png 和 0910x2.bmp\n",
            "处理图像: 0908x2.png 和 0911x2.bmp\n",
            "文件名不匹配: 0908x2.png 和 0911x2.bmp\n",
            "处理图像: 0905x2.png 和 0912x2.bmp\n",
            "文件名不匹配: 0905x2.png 和 0912x2.bmp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def load_images_from_folder(folder, file_extension):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith(file_extension):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is not None:\n",
        "                images.append((filename, img))\n",
        "    return images\n",
        "\n",
        "def annotate_image(image, text):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(image, text, (10, 30), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "    return image\n",
        "\n",
        "def resize_images(orig_img, super_res_img):\n",
        "    # 调整超分图像的大小以匹配原始图像的宽度和高度\n",
        "    height, width = orig_img.shape[:2]\n",
        "    super_res_resized = cv2.resize(super_res_img, (width, height))\n",
        "    return super_res_resized\n",
        "\n",
        "def concatenate_images(original_folder, super_res_folder, output_folder):\n",
        "    original_images = load_images_from_folder(original_folder, '.png')[:12]\n",
        "    super_res_images = load_images_from_folder(super_res_folder, '.bmp')[:12]\n",
        "\n",
        "    print(f\"找到 {len(original_images)} 张原始图像和 {len(super_res_images)} 张超分图像。\")\n",
        "\n",
        "    combined_rows = []\n",
        "\n",
        "    for orig_name, orig_img in original_images:\n",
        "        orig_prefix = orig_name[:-4]\n",
        "        matched = False\n",
        "\n",
        "        for super_res_name, super_res_img in super_res_images:\n",
        "            super_res_prefix = super_res_name[:-4]\n",
        "\n",
        "            if orig_prefix in super_res_prefix:\n",
        "                matched = True\n",
        "\n",
        "                # 调整超分图像大小\n",
        "                super_res_img_resized = resize_images(orig_img, super_res_img)\n",
        "\n",
        "                # 添加标注\n",
        "                orig_img_annotated = annotate_image(orig_img.copy(), \"Original\")\n",
        "                super_res_img_annotated = annotate_image(super_res_img_resized.copy(), \"Super Res\")\n",
        "\n",
        "                # 将原图和超分图像放入同一行\n",
        "                combined_row = np.hstack((orig_img_annotated, super_res_img_annotated))\n",
        "                combined_rows.append(combined_row)\n",
        "                break\n",
        "\n",
        "        if not matched:\n",
        "            print(f\"未找到匹配的超分图像: {orig_name}\")\n",
        "\n",
        "    # 确保有足够的行以形成 6 行 4 列\n",
        "    while len(combined_rows) < 6:\n",
        "        # 创建一个与已存在行相同大小的空白行\n",
        "        if combined_rows:\n",
        "            empty_row = np.zeros_like(combined_rows[0])\n",
        "        else:\n",
        "            empty_row = np.zeros((500, 2040, 3), dtype=np.uint8)  # 500 是高度，2040 是宽度，可根据需要调整\n",
        "        combined_rows.append(empty_row)\n",
        "\n",
        "    # 调整每一行的宽度一致\n",
        "    max_width = max(row.shape[1] for row in combined_rows)\n",
        "    for i in range(len(combined_rows)):\n",
        "        if combined_rows[i].shape[1] < max_width:\n",
        "            pad_width = max_width - combined_rows[i].shape[1]\n",
        "            padding = np.zeros((combined_rows[i].shape[0], pad_width, 3), dtype=np.uint8)\n",
        "            combined_rows[i] = np.hstack((combined_rows[i], padding))\n",
        "\n",
        "    # 最终拼接成 6 行\n",
        "    combined_image = np.vstack(combined_rows)\n",
        "\n",
        "    output_path = os.path.join(output_folder, 'combined_image.png')\n",
        "    cv2.imwrite(output_path, combined_image)\n",
        "    print(f\"生成拼接图像: {output_path}\")\n",
        "\n",
        "\n",
        "# 设置文件夹路径\n",
        "original_folder = 'DIV2K/DIV2K/DIV2K_test_LR_unknown/X2'  # PNG 文件夹路径\n",
        "super_res_folder = 'results/swinir_real_sr_x2'  # BMP 文件夹路径\n",
        "output_folder = 'results'  # 输出文件夹路径\n",
        "\n",
        "# 创建输出文件夹（如果不存在）\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 执行拼接\n",
        "concatenate_images(original_folder, super_res_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5poOiEks6ojd",
        "outputId": "c747d74c-91e9-4f3e-f72e-968db7f030c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "找到 12 张原始图像和 12 张超分图像。\n",
            "生成拼接图像: results/combined_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Airujing/Super_Resolution.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js135e0MFvo8",
        "outputId": "c186ad97-938d-4b77-e0fb-d05faf0f2f5d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Super_Resolution'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (6/6), done.\n"
          ]
        }
      ]
    }
  ]
}